# ğŸ® Rich CLI Control Center Guide

## ğŸš€ Overview

The **Rich CLI** is Ollama Jack's centralized command and control center. Think of it as your **mission control** for the entire AI workspace system - you can monitor, configure, and control everything from this single interface.

## ğŸ“‹ Complete Command Reference

### ğŸ¤– **AI Models**
```bash
models           # Scan and list all available AI models
select           # Interactive model selector with arrow keys
use <model>      # Switch to specific model directly
next             # Cycle to next available model
prev             # Cycle to previous available model
chat             # Start direct AI conversation
generate <text>  # Generate AI text response
```

### ğŸ”§ **System Controls**
```bash
auto-accept on   # Enable automatic edit approval (dangerous!)
auto-accept off  # Disable automatic edit approval (recommended)
status           # Complete system health dashboard
restart          # Restart all Ollama Jack services
debug            # Toggle debug analysis mode
clear            # Clear terminal and reset display
help             # Show complete command reference
exit             # Exit Rich CLI interface
```

### ğŸ“Š **Analytics & Monitoring**
```bash
usage            # Web search usage tracking and limits
usage-models     # Detailed model performance analytics
monitor          # Show system monitoring status
tokenomics       # Display API resource usage
```

### ğŸŒ **Mode & Configuration**
```bash
mode             # Show available operation modes
mode local       # Switch to local Ollama operation
mode cloud       # Switch to cloud Ollama operation
local            # Quick switch to local mode
cloud            # Quick switch to cloud mode
```

### ğŸ› ï¸ **Workspace Operations**
```bash
ide-info         # Show current IDE information
workspace        # Analyze workspace structure
tools            # List available AI tools
```

### ğŸ“¦ **Model Management**
```bash
pull <model>     # Download AI model from Ollama
push <model>     # Upload model to Ollama cloud
rm <model>       # Remove local AI model
```

## ğŸ¯ Key Features

### ğŸ“Š **System Status Dashboard**
The `status` command provides a comprehensive overview:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SYSTEM STATUS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Status: jacked-in        â”‚ Workspace: my-project      â”‚
â”‚ Mode: CLOUD              â”‚ Port: 11435                â”‚
â”‚ Model: gpt-oss:120b      â”‚ Active Terms: 3            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Auto-Accept: âŒ Disabled â”‚ Edit Mode: Manual           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Web Searches: 15/100 used (85 remaining)               â”‚
â”‚ Reset Time: 2025-09-28T00:00:00Z â”‚ Daily Budget: 15%  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Services Status:                                        â”‚
â”‚   â€¢ Main Hijacker     ğŸŸ¢ ONLINE  (Port 11435)         â”‚
â”‚   â€¢ Rich CLI          ğŸŸ¢ ACTIVE  (Interactive)        â”‚
â”‚   â€¢ Telemetry Manager ğŸŸ¢ ONLINE  (Analytics)          â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ”§ Active Capabilities:
  â€¢ ğŸ¤– AI Model Communication & Tool Execution
  â€¢ ğŸ“ Full Workspace File Access & Modification  
  â€¢ ğŸ’» Terminal Command Execution
  â€¢ ğŸ” Real-time Code Search & Analysis
  â€¢ ğŸ“Š Usage Tracking & Performance Monitoring
  â€¢ âš¡ Multi-model Cloud & Local Support
```

### ğŸ¤– **Interactive Model Selector**
The `select` command opens a visual model picker:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODEL SELECTOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚   gpt-oss:20b      [20B params]      â”‚
â”‚ ğŸ¯ gpt-oss:120b    [120B params]     â”‚ â† Selected
â”‚   deepseek-v3.1    [671B params]     â”‚
â”‚   qwen3-coder      [480B params]     â”‚
â”‚   kimi-k2          [1T params]       â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

â†‘â†“ Navigate  ENTER Select  ESC Cancel
```

### ğŸ“ˆ **Model Usage Analytics**
The `usage-models` command shows detailed performance data:

```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ MODEL USAGE DATA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ Reset Date: 2025-09-27 08:00         Daily Stats: 45   â”‚
â”‚ Overall Success Rate: 94%            Rate Limits: 2    â”‚  
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸŸ¢ gpt-oss:120b     â”‚ 23 req â”‚ 96% â”‚ 0 limits          â”‚
â”‚   â””â”€ Tokens: 15,420 total, 670 avg/req                  â”‚
â”‚   â””â”€ Max consecutive tool calls: 8                       â”‚
â”‚ ğŸŸ¡ qwen3-coder:480b â”‚ 12 req â”‚ 83% â”‚ 2 limits          â”‚
â”‚   â””â”€ âš ï¸ 2 rate limit errors detected!                   â”‚
â”‚   â””â”€ Tool call #4 failed at 14:23:45                    â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯

ğŸ’¡ Some models have limits on consecutive tool calls - 
    consider switching models for long sequences!
```

## ğŸ›¡ï¸ **Safety & Security Features**

### ğŸ® **Auto-Accept Control**
The most important safety feature - control whether AI edits are applied automatically:

```bash
# RECOMMENDED: Manual approval for all edits
Rich CLI > auto-accept off
â¸ï¸  Auto-accept mode disabled - manual approval required
ğŸ’¡ Use 'auto-accept on' to enable

# DANGEROUS: Automatic edit approval (use with caution)
Rich CLI > auto-accept on  
ğŸ¤– Auto-accept mode enabled - edits will be applied automatically
ğŸ’¡ Use 'auto-accept off' to disable
```

### ğŸ“Š **Service Health Monitoring**
Rich CLI continuously monitors all system components:
- **Main Hijacker** (Port 11435) - Core AI system and tool execution
- **Telemetry Manager** - Analytics and performance tracking
- **Session Memory** - Conversation context and state management
- **Edit Controller** - Human-in-the-loop approval system

### ğŸ”„ **Auto-Loading Models**
Rich CLI automatically loads model lists when needed:
- No more empty model selectors
- Smart caching of model data
- Fallback to cached data if API is unavailable

## ğŸš€ **Advanced Capabilities** (Theoretical)

The Rich CLI architecture supports complete remote control of the hijacker via API endpoints:

### ğŸ¯ **Available API Control Points**
- `/hijack/execute` - Execute any tool directly
- `/hijack/switch-mode` - Change operation modes
- `/jack/auto-accept` - Toggle edit approval
- `/v1/chat/completions` - Send AI messages
- `/api/model` - Switch models

### ğŸ’¥ **Potential Remote Operations**
- **File Operations** - Read/write any workspace file
- **Terminal Commands** - Execute shell commands remotely
- **AI Chat** - Send messages to AI from Rich CLI
- **Tool Execution** - Use any available tool directly
- **Workspace Analysis** - Full codebase scanning

## ğŸ¯ **Best Practices**

### ğŸ›¡ï¸ **Security Recommendations**
1. **Always use `auto-accept off`** unless rapid prototyping
2. **Monitor system status regularly** with `status` command
3. **Check model usage** to avoid rate limits with `usage-models`
4. **Use `next`/`prev` to switch models** when hitting limits

### âš¡ **Performance Tips**
1. **Use `select` for visual model picking** - faster than typing names
2. **Check `usage` before intensive operations** - avoid quota limits
3. **Use `restart` if services become unresponsive**
4. **Monitor with `status`** to catch issues early

### ğŸ® **Workflow Optimization**
1. **Start with `models`** to see what's available
2. **Use `select`** to pick optimal model for your task
3. **Enable `auto-accept on`** only for trusted operations
4. **Check `usage-models`** to understand model performance patterns

---

**ğŸ® Rich CLI = Complete System Control** - Your AI workspace, your rules! ğŸ›¡ï¸âš¡