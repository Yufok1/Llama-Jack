# Llama Jack Environment Configuration Template
# Copy this file to .env and customize with your settings

# =============================================================================
# SERVER CONFIGURATION
# =============================================================================

# Main HTTP server port for the AI assistant
PORT=11435

# Debug server port for development debugging
DEBUG_PORT=11436

# Monitoring server port for system metrics
MONITOR_PORT=11437

# =============================================================================
# OLLAMA CONFIGURATION
# =============================================================================

# Operation mode: "local" for local Ollama, "cloud" for Ollama Cloud API
MODE=cloud

# Ollama Cloud API key (required when MODE=cloud)
# Get your API key from: https://cloud.ollama.com/api-keys
OLLAMA_API_KEY=your_ollama_cloud_api_key_here

# Local Ollama server URL (used when MODE=local)
OLLAMA_HOST=http://localhost:11434

# Default AI model to use
DEFAULT_MODEL=llama3.2:3b

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Logging level: ERROR, WARN, INFO, DEBUG, TRACE
JACK_LOG_LEVEL=INFO

# Enable/disable debug output
DEBUG=false

# =============================================================================
# WORKSPACE TARGETING
# =============================================================================

# Target workspace directory (optional - defaults to current directory)
HIJACK_TARGET_WORKSPACE=

# Project type for specialized handling: node, python, generic
HIJACK_PROJECT_TYPE=generic

# =============================================================================
# CANVAS INTEGRATION
# =============================================================================

# Canvas integration server URL
CANVAS_SERVER_URL=http://localhost:8000

# Enable Canvas-Jack resource orchestration
CANVAS_INTEGRATION=true

# =============================================================================
# TELEMETRY AND ANALYTICS
# =============================================================================

# Disable telemetry collection (set to true to disable data collection)
JACK_NO_FOOTPRINT=false

# Enable usage statistics
ENABLE_TELEMETRY=true

# =============================================================================
# AI BEHAVIOR CONFIGURATION
# =============================================================================

# Auto-accept edit proposals (be careful with this setting!)
AUTO_ACCEPT_EDITS=false

# Maximum tokens for AI context
MAX_CONTEXT_TOKENS=128000

# Tool execution timeout in seconds
TOOL_TIMEOUT=30

# =============================================================================
# ADVANCED FEATURES
# =============================================================================

# Enable alignment engine safety checks
ALIGNMENT_ENGINE_ENABLED=true

# Enable surgical edit pre-read enforcement
SURGICAL_EDIT_PRE_READ=true

# Enable meta-constraint enhancement optimization
META_CONSTRAIN_ENHANCEMENT=true

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Enable development mode
NODE_ENV=development

# Enable test mode
TEST_MODE=false

# Enable verbose output for troubleshooting
VERBOSE=false